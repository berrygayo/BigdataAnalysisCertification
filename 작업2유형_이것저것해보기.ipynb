{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "작업2유형_이것저것해보기.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1X9ZVXzIG5rIabOddzUhb1yHSx--1jzu3",
      "authorship_tag": "ABX9TyOFydiju03LDKqY9PSmXMEn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berrygayo/BigdataAnalysisCertification/blob/main/%EC%9E%91%EC%97%852%EC%9C%A0%ED%98%95_%EC%9D%B4%EA%B2%83%EC%A0%80%EA%B2%83%ED%95%B4%EB%B3%B4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwfjg0wHn_yB"
      },
      "source": [
        "# 로지스틱 회귀분석 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO7ZOxgwoxYg"
      },
      "source": [
        "%%time \n",
        "# ms : 밀리세컨즈 (1000ms = 1s) \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_train2, X_val,y_train2, y_val = train_test_split(X_train, y_train, random_state=0)\n",
        "# 로지스틱 \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LogisticR = LogisticRegression().fit(X_train2,y_train2)\n",
        "print(\"Logistic Regression train score : {:.2f}\".format(LogisticR.score(X_train2, y_train2)))\n",
        "print(\"Logistic Regression validation score : {:.2f}\".format(LogisticR.score(X_val, y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc2XJTmEbD0U"
      },
      "source": [
        "# 랜덤포레스트 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKnovrg4bIYg"
      },
      "source": [
        "%%time \n",
        "# ms : 밀리세컨즈 (1000ms = 1s) \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_train2, X_val,y_train2, y_val = train_test_split(X_train, y_train, random_state=0)\n",
        "# randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF = RandomForestClassifier(max_depth=2,n_estimators=5).fit(X_train2,y_train2)\n",
        "print(\"RandomForestClassifier train score : {:.2f}\".format(RF.score(X_train2, y_train2)))\n",
        "print(\"RandomForestClassifier validation score : {:.2f}\".format(RF.score(X_val, y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx55xjGmUzui"
      },
      "source": [
        "## 랜덤포레스트 모델 roc score 확인 \n",
        "### vali data 없이 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF0-49wrU3qz"
      },
      "source": [
        "%%time \n",
        "# ms : 밀리세컨즈 (1000ms = 1s) \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "#X_train2, X_val,y_train2, y_val = train_test_split(X_train, y_train, random_state=0)\n",
        "# randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF = RandomForestClassifier(max_depth=2, n_estimators=5).fit(X_train,y_train)\n",
        "print(\"RandomForestClassifier train score : {:.2f}\".format(RF.score(X_train, y_train)))\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#print(RF.predict_proba(X_train))\n",
        "roc_auc_score = roc_auc_score(y_train, RF.predict_proba(X_train)[:,1])\n",
        "print(\"roc_auc_score : {:.2f}\".format(roc_auc_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuAXQ-Mefayq"
      },
      "source": [
        "RF.predict_proba(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcuiBxWMbyLR"
      },
      "source": [
        "# 만약 y 예측값을 제출하라 그러면 이렇게 하면됨 \n",
        "RF.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpRnQyLdbxGt"
      },
      "source": [
        "RF.predict_proba(X_train)[:,1]\n",
        "# 남자일 확률을 뽑아줌"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L5y93cIU3s7"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pzjgdLlbFeR"
      },
      "source": [
        "# XGBoost "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI40nboYbFgJ"
      },
      "source": [
        "%%time \n",
        "# ms : 밀리세컨즈 (1000ms = 1s) \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_train2, X_val,y_train2, y_val = train_test_split(X_train, y_train, random_state=0)\n",
        "# xgboost \n",
        "from xgboost import XGBClassifier\n",
        "XGB = XGBClassifier().fit(X_train2,y_train2)\n",
        "print(\"XGB.score train score : {:.2f}\".format(XGB.score(X_train2, y_train2)))\n",
        "print(\"XGB.score validation score : {:.2f}\".format(XGB.score(X_val, y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jThiX2QX2-q"
      },
      "source": [
        "# 교차검증 cv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCMylpq4YEsu"
      },
      "source": [
        "%%time \n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "#X_train2, X_val,y_train2, y_val = train_test_split(X_train, y_train, random_state=0)\n",
        "# 로지스틱 \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "LogisticR = LogisticRegression().fit(X_train2,y_train2)\n",
        "\n",
        "# 교차검증\n",
        "scores = cross_val_score(LogisticR, X_train,y_train,cv=10)\n",
        "scores\n",
        "\n",
        "print(\"Logistic Regression train score : {:.2f}\".format(scores.mean()))\n",
        "#print(\"Logistic Regression validation score : {:.2f}\".format(LogisticR.score(X_val, y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruxf6cEXQJJG"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vaCXNr2Llp3"
      },
      "source": [
        "%%time \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "# n 을 설정하는 방법 \n",
        "# 임의의 높은 수 n 으로 진행한 후 누적분산 설명력 확인 \n",
        "pca = PCA(n_components = 6)\n",
        "principalComponents = pca.fit_transform(X_train)\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# 6번째 주성분 0.07로 현저히 낮으므로 5개로 진행한다. \n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3) #주성분을 몇개로 할지\n",
        "principalComponents = pca.fit_transform(X_train)\n",
        "principalDF = pd.DataFrame(data=principalComponents, columns = ['PC1', '\"PC2', 'PC3']) \n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# X_train2, X_test2,y_train2, y_test2 = train_test_split(X_train, y_train, random_state=0)\n",
        "X_train2, X_val,y_train2, y_val = train_test_split(principalDF, y_train, random_state=0)\n",
        "\n",
        "# 로지스틱 \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LogisticR = LogisticRegression().fit(X_train2,y_train2)\n",
        "print(\"Logistic Regression train score : {:.2f}\".format(LogisticR.score(X_train2, y_train2)))\n",
        "print(\"Logistic Regression validation score : {:.2f}\".format(LogisticR.score(X_val, y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDT-LvuDpm_G"
      },
      "source": [
        "## cor 낮은거 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EywbCSZQUFi"
      },
      "source": [
        "%%time \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)\n",
        "# 데이터 스플릿 \n",
        "X_train = data_set.drop(['gender'], axis=1 )\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "data_set.corr()\n",
        "# 주구매상품, 주구매지점, 내점당구매건수, 주말방문비율 제거 \n",
        "X_train = data_set.loc[:, ['총구매액','최대구매액','환불금액','내점일수','구매주기']]\n",
        "y_train = data_set.loc[:,'gender']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "# standardscaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_train2, X_val,y_train2, y_val = train_test_split(X_train, y_train, random_state=0)\n",
        "\n",
        "# 로지스틱 \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LogisticR = LogisticRegression().fit(X_train2,y_train2)\n",
        "print(\"Logistic Regression train score : {:.2f}\".format(LogisticR.score(X_train2, y_train2)))\n",
        "print(\"Logistic Regression validation score : {:.2f}\".format(LogisticR.score(X_val, y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx8FHEiMJWMm"
      },
      "source": [
        "# 내기준 최고 점수 63점 \n",
        "# 다른분 풀이 참고"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhUqeZCkIv9U"
      },
      "source": [
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlSpmB8CFNSk"
      },
      "source": [
        "data_set.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfVfsjBuoQM2"
      },
      "source": [
        "# 파생변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S_oJOTloQOz"
      },
      "source": [
        "data_set['최초구매액'] = data_set['총구매액'] + data_set['환불금액'] + 1 \n",
        "# +1 은 왜 한걸까 ? 0이 되는 케이스 방지 ?\n",
        "data_set['최대구매액비율'] = data_set['최대구매액'] / data_set['최초구매액'] \n",
        "data_set['환불금액비율'] = data_set['환불금액']/data_set['최초구매액']\n",
        "data_set['총구매건수'] = data_set['내점일수']*data_set['내점당구매건수']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF1_7T6dFKSS"
      },
      "source": [
        "data_set.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz81H-hoFKF4"
      },
      "source": [
        "data_set['최초구매액2'] = data_set['총구매액'] + data_set['환불금액'] \n",
        "data_set['최초구매액2'].min()\n",
        "del data_set['최초구매액2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG-pmd3QoQTN"
      },
      "source": [
        "# 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGia3LpeMeTY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "# 데이터 스플릿 \n",
        "X = data_set.drop(['gender'], axis=1 )\n",
        "y= data_set.loc[:,'gender']\n",
        "\n",
        "# train 데이터셋 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=60, stratify=y)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', XGBClassifier())])\n",
        "\n",
        "# 교차검증\n",
        "scores = cross_val_score(my_pipeline, X, y, \n",
        "                              cv=5,\n",
        "                              scoring='roc_auc')\n",
        "\n",
        "print(\"scores:\\n\", scores)\n",
        "print(\"\\nAverage score:\")\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoIkcSkdMeVU"
      },
      "source": [
        "# 모델 선택 및 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TAhyctkMeXV"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('model', XGBClassifier())])\n",
        "\n",
        "param_grid = [{'model': [SVC()], \n",
        "              'model__gamma': [0.01, 0.1, 1, 10, 100], \n",
        "              'model__C': [0.01, 0.1, 1, 10, 100]\n",
        "              },\n",
        "\n",
        "              {'model': [XGBClassifier()], \n",
        "              'model__learning_rate' : [0.1, 0.3, 0.5],\n",
        "              'model__n_estimators' : [50, 100, 200,],  \n",
        "              'model__max_depth': [3, 4, 6]\n",
        "              },\n",
        "\n",
        "              {'model': [RandomForestClassifier()],\n",
        "              'model__max_depth': [3, 4, 6], \n",
        "              'model__n_estimators': [50, 100, 200], \n",
        "              'model__min_samples_split': [50, 100]\n",
        "              }]        \n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, scoring = 'roc_auc', cv=5)  \n",
        "grid.fit(X, y)\n",
        "\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enK09hg-UJac"
      },
      "source": [
        "# 최종 모델 결정 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO5Zm74wUJc2"
      },
      "source": [
        "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', XGBClassifier(n_estimators=200, max_depth=3))])\n",
        "\n",
        "\n",
        "scores = cross_val_score(my_pipeline, X, y, \n",
        "                              cv=5,\n",
        "                              scoring='roc_auc')\n",
        "\n",
        "print(\"scores:\\n\", scores)\n",
        "print(\"\\nAverage score:\")\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QadYlnevUJfD"
      },
      "source": [
        "# 시간 재보기 \n",
        "%%time \n",
        "\n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_test.csv',encoding='euc-kr')\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/X_train.csv',encoding='euc-kr')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Bigdata_study/빅분기 실기 준비/실습/[Dataset] 작업형 제2유형/y_train.csv',encoding='euc-kr')\n",
        "# cust_id 기준 합치기 \n",
        "data_set=pd.merge(X_train, y_train,on='cust_id')\n",
        "\n",
        "# 결측치처리\n",
        "data_set=data_set.fillna(0)\n",
        "# 음수 데이터 제거 \n",
        "data_set = data_set.query('총구매액>=0 and 최대구매액>=0')\n",
        "\n",
        "# 범주형 데이터 > 레이블링 \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "data_set['주구매상품']=LabelEncoder().fit_transform(data_set['주구매상품'])\n",
        "data_set['주구매지점']=LabelEncoder().fit_transform(data_set['주구매지점'])\n",
        "#cust_id는 빼고 분석\n",
        "data_set=data_set.drop(['cust_id'],axis=1) \n",
        "\n",
        "#파생변수 생성 \n",
        "data_set['최초구매액'] = data_set['총구매액'] + data_set['환불금액'] + 1 \n",
        "data_set['최대구매액비율'] = data_set['최대구매액'] / data_set['최초구매액'] \n",
        "data_set['환불금액비율'] = data_set['환불금액']/data_set['최초구매액']\n",
        "data_set['총구매건수'] = data_set['내점일수']*data_set['내점당구매건수']\n",
        "\n",
        "# 모델링 \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "# 데이터 스플릿 \n",
        "X = data_set.drop(['gender'], axis=1 )\n",
        "y= data_set.loc[:,'gender']\n",
        "\n",
        "# train 데이터셋 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=60, stratify=y)\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', XGBClassifier())])\n",
        "\n",
        "# 교차검증\n",
        "scores = cross_val_score(my_pipeline, X, y, \n",
        "                              cv=5,\n",
        "                              scoring='roc_auc')\n",
        "\n",
        "print(\"scores:\\n\", scores)\n",
        "print(\"\\nAverage score:\")\n",
        "print(scores.mean()) \n",
        "\n",
        "# 모델 선택 및 튜닝 \n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('model', XGBClassifier())])\n",
        "\n",
        "param_grid = [{'model': [SVC()], \n",
        "              'model__gamma': [0.01, 0.1, 1, 10, 100], \n",
        "              'model__C': [0.01, 0.1, 1, 10, 100]\n",
        "              },\n",
        "\n",
        "              {'model': [XGBClassifier()], \n",
        "              'model__learning_rate' : [0.1, 0.3, 0.5],\n",
        "              'model__n_estimators' : [50, 100, 200,],  \n",
        "              'model__max_depth': [3, 4, 6]\n",
        "              },\n",
        "\n",
        "              {'model': [RandomForestClassifier()],\n",
        "              'model__max_depth': [3, 4, 6], \n",
        "              'model__n_estimators': [50, 100, 200], \n",
        "              'model__min_samples_split': [50, 100]\n",
        "              }]        \n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, scoring = 'roc_auc', cv=5)  \n",
        "grid.fit(X, y)\n",
        "\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)\n",
        "\n",
        "# 최종모델 결정 \n",
        "my_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('model', XGBClassifier(n_estimators=200, max_depth=3))])\n",
        "\n",
        "\n",
        "scores = cross_val_score(my_pipeline, X, y, \n",
        "                              cv=5,\n",
        "                              scoring='roc_auc')\n",
        "\n",
        "print(\"scores:\\n\", scores)\n",
        "print(\"\\nAverage score:\")\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}